{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "CLASES = 2\n",
    "PREF = 'B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PREF + \"/mnist2_train.txt\", 'r') as fin:\n",
    "    data = [list(map(int, line.split())) for line in fin.readlines()]\n",
    "X = np.array([line[:-1] for line in data])\n",
    "Y = np.array([line[-1] for line in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sum(nn.Module):\n",
    "    def __init__(self, inp, oup):\n",
    "        super(self.__class__, self).__init__()\n",
    "        \n",
    "    \n",
    "    def forward(self, X):\n",
    "        return X.reshape(-1, CLASES, 15).sum(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(batch):\n",
    "    for i in range(batch.shape[0]):\n",
    "        for j in range(3):\n",
    "            val = np.random.randint(0, 50)\n",
    "            batch[i][val] *= -1\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(X, Y, batch_size=32):\n",
    "    indexes = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indexes)\n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        first = i\n",
    "        last = min(X.shape[0], i + batch_size)\n",
    "        yield augmentation(X[indexes[first:last]]), Y[indexes[first:last]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Dropout(p=0),\n",
    "    nn.Linear(51, 15 * CLASES, bias=False),\n",
    "    Sum(15 * CLASES, CLASES),\n",
    "    nn.Softmax()\n",
    ")\n",
    "\n",
    "num_epochs = 20 # total amount of full passes over training data\n",
    "batch_size = 50  # number of samples processed in one SGD iteration\n",
    "opt = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143.10733154416084\n",
      "137.32735660672188\n",
      "137.18085622787476\n",
      "136.87308591604233\n",
      "137.1068505346775\n",
      "137.20916536450386\n",
      "136.63939279317856\n",
      "137.2351368367672\n",
      "137.38753905892372\n",
      "137.33831039071083\n",
      "137.1970399916172\n",
      "136.19979819655418\n",
      "137.44092571735382\n",
      "137.14024087786674\n",
      "137.22035402059555\n",
      "137.30909436941147\n",
      "137.43693923950195\n",
      "137.4540996849537\n",
      "136.33678925037384\n",
      "136.55148831009865\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    all_loss = 0\n",
    "    for x_batch, y_batch in get_batch(X, Y):\n",
    "        x_batch = Variable(torch.Tensor(x_batch))\n",
    "        y_batch = Variable(torch.LongTensor(y_batch))\n",
    "        res = model.forward(x_batch)\n",
    "        loss = F.cross_entropy(res, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        all_loss += loss.data.numpy()\n",
    "    print(all_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = model.state_dict().get('1.weight').data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PREF + '/res', 'w') as fout:\n",
    "    for i in range(values.shape[0]):\n",
    "        fout.write(' '.join(list(map(str, values[i]))))\n",
    "        fout.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "with open(PREF + '/res2', 'r') as fout:\n",
    "    for i in range(15 * CLASES):\n",
    "        line = fout.readline()\n",
    "        values.append(list(map(float, line.split())))\n",
    "values = np.array(values)\n",
    "\n",
    "with open(PREF + '/res.cpp', 'w') as fout:\n",
    "    fout.write(\"#include<iostream>\\n\")\n",
    "    fout.write(\"using namespace std;\\n\")\n",
    "    fout.write(\"int main() {\\n\")\n",
    "    for i in range(values.shape[0]):\n",
    "        fout.write('cout << \"')\n",
    "        fout.write(' '.join(list(map(str, values[i]))))\n",
    "        fout.write('\" << endl;\\n')\n",
    "    fout.write(\"}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
